---
title: "STAT_4870_Project"
author: "Waleed Abdulla"
date: "2025-04-17"
output: html_document
---

#Simple/Multiple Lin Reg doesn't count but can be used for comparison
#PCA
#AIC
#BIC
#Log Regression
#QDA/LDA
#kNN

New Libraries: fastDummies, patchwork

Libraries
```{r, include=FALSE}
library(MASS)
library(fpp3)
library(fastDummies)
library(patchwork)
library(rsample)
library(factoextra)
library(car)
```


```{r}
Bank <- read.csv("C:/Users/13147/Documents/bankmarketing/bank-full.csv", sep = ";")
Bank %>% tail()
```

Step 1: What question are we trying to answer?

 - Predict if the client will subscribe to a term deposit (variable y).
    - Find the key predictors 
    - Create a good applied regression model.
 
 
Step 2: Clean our data.

Before creating indicator variables for our categorical predictors, we need to find outliers. With categorical predictors, outliers are based on the size of the variable relative to the size of the entire column. For example:
  
```{r}
Bank %>% ggplot(aes(x = job)) +
geom_bar(fill = "blue") + labs(x='Team') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The "unknown" variable is undoubtedly an outlier since it has a small count compared to the 40,000+ dataset. Let's remove it and look at the following bar plot:

```{r}
Bank <- Bank %>% filter(job != "unknown")
Bank %>% ggplot(aes(x = job)) +
geom_bar(fill = "blue") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Now let's look at the other categorical variables for potential outliers.

```{r}
p1 <- Bank %>% ggplot(aes(x = marital)) + geom_bar(fill = "blue")
p2 <- Bank %>% ggplot(aes(x = default)) + geom_bar(fill = "blue")
p3 <- Bank %>% ggplot(aes(x = housing)) + geom_bar(fill = "blue")
p4 <- Bank %>% ggplot(aes(x = loan)) + geom_bar(fill = "blue")
p5 <- Bank %>% ggplot(aes(x = contact)) + geom_bar(fill = "blue")
p6 <- Bank %>% ggplot(aes(x = month)) + geom_bar(fill = "blue") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p7 <- Bank %>% ggplot(aes(x = poutcome)) + geom_bar(fill = "blue")

# Arrange them in a grid
(p1 | p2 | p3) / (p4 | p5 | p6) / p7

```

There are no outliers in the marital variable. The default variable does have outliers, but we predict that whether or not someone defaulted on a loan highly affects whether or not they will subscribe to a term deposit, so we will keep it. There are no outliers in the housing, loan, or contact variables. Since months are temporal, removing outliers may affect the regression model. Finally, since the poutcome variable consists mostly of unknown, we'll remove it since it provides no real information.

```{r}
Bank <- Bank %>% select(-poutcome)
```

Now we need to create indicator variables for our categorical predictors
  
```{r}
Bank %>% select_if(is.character) %>% select(-y) %>% head(3)
```
There are 8 categorical indicators. Luckily, the fastDummies package automatically creates dummy variables for each categorical indicator. The package also allows us to remove the first dummy of every variable such that only n-1 dummies remain, avoiding multicollinearity issues in the future.

```{r}
BankN <- Bank %>% dummy_cols(select_columns = c("job", "marital", "education", "default", "housing", "loan", "contact", "y"), remove_first_dummy = TRUE) %>% select(-c("job", "marital", "education", "default", "housing", "loan", "contact","y")) %>% as.data.frame()

str(BankN)
```

Now, if we want to use a categorical variable, we'll use a preset filter that locates the relevant columns. We can even create a matrix. For example, say we want to use the *job* column. Note that if a row contains all 0 within the "job" columns, the job is "unknown"

```{r}
BankN %>% select(starts_with("job")) %>% as.matrix() %>% head()
```
We rename the binary variables:

```{r}
BankN <- BankN %>% rename(default = default_yes, housingLoan = housing_yes, personalLoan = loan_yes, y = y_yes)
```

Since the "month" variable is an ordinal variable, we can change the months to 1 through 12.

```{r}
monthToNum <- c("jan" = 1, "feb" = 2, "mar" = 3, "apr" = 4, "may" = 5, "jun" = 6,
                "jul" = 7, "aug" = 8, "sep" = 9, "oct" = 10, "nov" = 11, "dec" = 12)

BankN <- BankN %>% mutate(month = as.integer(monthToNum[month]))
```


The *campaign* column is the number of contacts performed *during* this campaign and the *previous* column is the number of contacts performed *before* this campaign. Let's combine both to get the total number of contacts. Since the "pdays" column relies on both columns, we'll remove that too.

```{r}
BankN <- BankN %>% mutate(contacts = campaign + previous) %>% select(-c("campaign","previous", "pdays"))
```

The *day* column and the *month* column are linked, so we can remove the *day* column all together. 

```{r}
BankN <- BankN %>% select(-day)
```

Final dataset (for now)
```{r}
BankN %>% head()
Bank %>% count(y)
```

Now let's look for obvious outliers within the quantitative variables:

age, balance, duration, and pdays (# of days before last campaign contact [-1 if N/A])

```{r}
p1 <- BankN %>% ggplot(aes(x = duration)) + geom_histogram()
p2 <- BankN %>% ggplot(aes(x = "", y = balance)) + geom_boxplot()
out <- boxplot.stats(BankN$balance)$out
BankN <- BankN %>% filter(!(balance %in% out))
p3 <- BankN %>% ggplot(aes(x = "", y = balance)) + geom_boxplot()
(p1 | p2 | p3)

p4 <- BankN %>% ggplot(aes(x=age)) + geom_histogram()
p5 <- BankN %>% ggplot(aes(x = "", y = age)) + geom_boxplot()
(p4 | p5)

p6 <- BankN %>% ggplot(aes(x = duration)) + geom_histogram()
p7 <- BankN %>% ggplot(aes(x = "", y = duration)) + geom_boxplot()
out <- boxplot.stats(BankN$duration)$out
BankN <- BankN %>% filter(!(duration %in% out))
p8 <- BankN %>% ggplot(aes(x = "", y = duration)) + geom_boxplot()
(p6 | p7 | p8)
```

Let's split the data. 

```{r}
set.seed(100)
split <- initial_split(BankN, prop = 0.7)
train <- training(split)
test <- testing(split)

trainx <- train %>% dplyr::select(-y)
trainy <- train %>% pull(y)
testx <- test %>% dplyr::select(-y)
testy <- test %>% pull(y)

dim(train)
dim(test)
```
Now let's make a PCA dataset to reduce dimensionality and normalize it.

```{r}
numeric_vars <- BankN |>
  select(age, balance, duration, month)

numeric_scaled <- scale(numeric_vars)

pca_result <- prcomp(numeric_scaled, center = TRUE, scale. = TRUE)

summary(pca_result)

library(factoextra)

#Show explained variance %
fviz_eig(pca_result, addlabels = TRUE)

pca_components <- as.data.frame(pca_result$x[, 1:3])
colnames(pca_components) <- c("PC1", "PC2", "PC3")
BankN
BankPCA <- BankN |>
  select(-age, -balance, -duration, -month) |>
  bind_cols(pca_components)
BankPCA
```

```{r}

lgmodel <- glm(y ~ ., data = BankN, family = binomial)

pcalgmodel <- glm(y ~ ., data = BankPCA, family = binomial)

lgmodel

pcalgmodel
```

Let's use LDA and QDA

```{r}
model1 = qda(trainx, trainy)
yhat <- predict(model1, newdata=testx)$class
table(yhat, testy)
mean(yhat == testy) #83.52 accuracy

model2 = lda(trainx, trainy)
yhat <- predict(model2, newdata=testx)$class
table(yhat, testy)
mean(yhat == testy) #91.26 accuracy
```
