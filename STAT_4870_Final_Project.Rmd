---
title: "STAT_4870_Project"
author: "Waleed Abdulla"
date: "2025-04-17"
output: html_document
---

#Simple/Multiple Lin Reg doesn't count but can be used for comparison
#PCA
#AIC
#BIC
#Log Regression
#QDA/LDA
#kNN

New Libraries: fastDummies, patchwork

Libraries
```{r, include=FALSE}
library(MASS)
library(fpp3)
library(fastDummies)
library(patchwork)
library(rsample)
library(factoextra)
library(car)
library(class)
```


```{r}
Bank <- read.csv("C:/Users/Panic/ML/appliedregression/bankmarketing/bank-full.csv", sep = ";")
#Bank <- read.csv("C:/Users/13147/Documents/bankmarketing/bank-full.csv", sep = ";")
Bank %>% tail()
```

Step 1: What question are we trying to answer?

 - Predict if the client will subscribe to a term deposit (variable y).
    - Find the key predictors 
    - Create a good applied regression model.
 
 
Step 2: Clean our data.

Before creating indicator variables for our categorical predictors, we need to find outliers. With categorical predictors, outliers are based on the size of the variable relative to the size of the entire column. For example:
  
```{r}
Bank %>% ggplot(aes(x = job)) +
geom_bar(fill = "blue") + labs(x='Team') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The "unknown" variable is undoubtedly an outlier since it has a small count compared to the 40,000+ dataset. Let's remove it and look at the following bar plot:

```{r}
Bank <- Bank %>% filter(job != "unknown")
Bank %>% ggplot(aes(x = job)) +
geom_bar(fill = "blue") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Now let's look at the other categorical variables for potential outliers.

```{r}
p1 <- Bank %>% ggplot(aes(x = marital)) + geom_bar(fill = "blue")
p2 <- Bank %>% ggplot(aes(x = default)) + geom_bar(fill = "blue")
p3 <- Bank %>% ggplot(aes(x = housing)) + geom_bar(fill = "blue")
p4 <- Bank %>% ggplot(aes(x = loan)) + geom_bar(fill = "blue")
p5 <- Bank %>% ggplot(aes(x = contact)) + geom_bar(fill = "blue")
p6 <- Bank %>% ggplot(aes(x = month)) + geom_bar(fill = "blue") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p7 <- Bank %>% ggplot(aes(x = poutcome)) + geom_bar(fill = "blue")

# Arrange them in a grid
(p1 | p2 | p3) / (p4 | p5 | p6) / p7

```

There are no outliers in the marital variable. The default variable does have outliers, but we predict that whether or not someone defaulted on a loan highly affects whether or not they will subscribe to a term deposit, so we will keep it. There are no outliers in the housing, loan, or contact variables. Since months are temporal, removing outliers may affect the regression model. Finally, since the poutcome variable consists mostly of unknown, we'll remove it since it provides no real information.

```{r}
Bank <- Bank %>% dplyr::select(-poutcome) %>% dummy_cols(select_columns = "y", remove_first_dummy = TRUE) %>% select(-y) %>% rename(y = y_yes)
```

Now we need to create indicator variables for our categorical predictors
  
```{r}
Bank %>% select_if(is.character) %>% head(3)
```

There are 8 categorical indicators. Luckily, the fastDummies package automatically creates dummy variables for each categorical indicator. The package also allows us to remove the first dummy of every variable such that only n-1 dummies remain, avoiding multicollinearity issues in the future.


Since the "month" variable is an ordinal variable, we can change the months to 1 through 12.

```{r}
monthToNum <- c("jan" = 1, "feb" = 2, "mar" = 3, "apr" = 4, "may" = 5, "jun" = 6,
                "jul" = 7, "aug" = 8, "sep" = 9, "oct" = 10, "nov" = 11, "dec" = 12)

Bank <- Bank %>% mutate(month = as.integer(monthToNum[month])) %>% mutate(job = factor(job), marital = factor(marital), education = factor(education), default = factor(default), housing = factor(housing), loan = factor(loan), contact = factor(contact))

table(Bank$default, Bank$y)
table(Bank$job, Bank$y)
table(Bank$housing, Bank$y)
table(Bank$loan, Bank$y)
table(Bank$contact, Bank$y)
table(Bank$education, Bank$y)

```


The *campaign* column is the number of contacts performed *during* this campaign and the *previous* column is the number of contacts performed *before* this campaign. Let's combine both to get the total number of contacts. Since the "pdays" column relies on both columns, we'll remove that too.

```{r}
Bank <- Bank %>% mutate(calls = campaign + previous) %>% dplyr::select(-c("previous", "pdays","campaign"))
```

The *day* column and the *month* column are linked, so we can remove the *day* column all together. 

```{r}
Bank <- Bank %>% dplyr::select(-day) 
#Bank <- Bank %>% filter(contact != "unknown", education != "unknown")
```

Final dataset (for now)
```{r}
Bank %>% head()
Bank %>% count(y)
```

Now let's look for obvious outliers within the quantitative variables:

age, balance, duration, and pdays (# of days before last campaign contact [-1 if N/A])

```{r}
p1 <- Bank %>% ggplot(aes(x = duration)) + geom_histogram()
p2 <- Bank %>% ggplot(aes(x = "", y = balance)) + geom_boxplot()
out <- boxplot.stats(Bank$balance)$out
Bank <- Bank %>% filter(!(balance %in% out))
p3 <- Bank %>% ggplot(aes(x = "", y = balance)) + geom_boxplot()
(p1 | p2 | p3)

p4 <- Bank %>% ggplot(aes(x=age)) + geom_histogram()
p5 <- Bank %>% ggplot(aes(x = "", y = age)) + geom_boxplot()
(p4 | p5)

p6 <- Bank %>% ggplot(aes(x = duration)) + geom_histogram()
p7 <- Bank %>% ggplot(aes(x = "", y = duration)) + geom_boxplot()
out <- boxplot.stats(Bank$duration)$out
Bank <- Bank %>% filter(!(duration %in% out))
p8 <- Bank %>% ggplot(aes(x = "", y = duration)) + geom_boxplot()
(p6 | p7 | p8)
```

Now let's make a PCA dataset to reduce dimensionality and normalize it.

```{r}
numeric_vars <- Bank |>
  dplyr::select(age, balance, duration, month, calls)

Bank
numeric_scaled <- scale(numeric_vars)

pca_result <- prcomp(numeric_scaled, center = TRUE, scale. = TRUE)

summary(pca_result)

library(factoextra)

#Show explained variance %
fviz_eig(pca_result, addlabels = TRUE)

pca_components <- as.data.frame(pca_result$x[, 1:4])
colnames(pca_components) <- c("PC1", "PC2", "PC3","PC4")

BankPCA <- Bank |>
  dplyr::select(-age, -balance, -duration, -month, -calls) |>
  bind_cols(pca_components)

#BankPCA <- Bank |> filter(contact != "unknown", education != "unknown") %>%
#  dplyr::select(-age, -balance, -duration, -month) |>
#  bind_cols(pca_components)

Bank|> filter(y==1) 2387
Bank|> filter(y==0) 31445
```


Let's split the data. 

```{r}
set.seed(100)
split <- initial_split(Bank, prop = 0.7)
train <- training(split)
test <- testing(split)

trainx <- train %>% dplyr::select(-y)
trainy <- train %>% pull(y)
testx <- test %>% dplyr::select(-y)
testy <- test %>% pull(y)

dim(train)
dim(test)


pcasplit <- initial_split(BankPCA, prop = 0.7)
pcatrain <- training(pcasplit)
pcatest <- testing(pcasplit)

pcatrainx <- pcatrain %>% dplyr::select(-y)
pcatrainy <- pcatrain %>% pull(y)
pcatestx <- pcatest %>% dplyr::select(-y)
pcatesty <- pcatest %>% pull(y)

dim(pcatrain)
dim(pcatest)
```

Use Logistic regression and use AIC and BIC to select variables.

```{r, cache=TRUE}
m0 <- glm(y ~ 1, data = train, family = binomial)
lgmodel <- glm(y ~ ., data = train, family = binomial)


# AIC
mAIC <- stepAIC(lgmodel,
                 scope = list(lower = m0, upper = lgmodel),
                 direction = "both", trace = FALSE)

# BIC
kBIC <- log(nrow(train))
mBIC <- stepAIC(lgmodel,
                 scope = list(lower = m0, upper = lgmodel),
                 direction = "both",
                 k = kBIC, trace = FALSE)

bestmodel <- if (AIC(mAIC) < AIC(mBIC)) formula(mAIC) else formula(mBIC)
bestmodel

pcam0 <- glm(y ~ 1, data = pcatrain, family = binomial)
pcalgmodel <- glm(y ~ ., data = pcatrain, family = binomial)

# AIC
pcamAIC <- stepAIC(pcalgmodel,
                 scope = list(lower = pcam0, upper = pcalgmodel),
                 direction = "both", trace = FALSE)

# BIC
pcakBIC <- log(nrow(pcatrain))
pcamBIC <- stepAIC(pcalgmodel,
                 scope = list(lower = pcam0, upper = pcalgmodel),
                 direction = "both",
                 k = pcakBIC, trace = FALSE)

pcabestmodel <- if (AIC(pcamAIC) < AIC(pcamBIC)) formula(pcamAIC) else formula(pcamBIC)
pcabestmodel

bestmodel <- glm(y ~ age + job + marital + education + default + balance + housing + 
    loan + contact + month + duration, data = train, family = binomial)


pcabestmodel <- glm(y ~ job + education + housing + loan + contact + PC1 + PC2 + 
    PC3 + PC4, data = pcatrain, family = binomial)
BankPCA

```


```{r, cache=TRUE}
probs <- predict(bestmodel, newdata = test, type = "response")
predicted_classes <- ifelse(probs > 0.5, 1, 0)
actual_classes <- test$y
accuracy <- mean(predicted_classes == actual_classes)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

probs <- predict(pcabestmodel, newdata = pcatest, type = "response")
predicted_classes <- ifelse(probs > 0.5, 1, 0)
actual_classes <- test$y
accuracy <- mean(predicted_classes == actual_classes)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))


yhat <- ifelse(predict(bestmodel, newdata = testx, type = "response") > 0.5, 1, 0)

hm <- as.data.frame(table(yhat, testy))

ggplot(hm, aes(x = yhat, y = testy, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(yhat == testy)

yhat <- ifelse(predict(pcabestmodel, newdata = pcatest, type = "response") > 0.5, 1, 0)

hm <- as.data.frame(table(yhat, testy))

ggplot(hm, aes(x = yhat, y = testy, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 30),
        axis.title.y = element_text(size = 30))

mean(yhat == testy)


```

Let's use LDA and QDA

```{r}


```


```{r}
split <- initial_split(Bank, prop = 0.7)
train <- training(split)
test <- testing(split)

trainx <- train %>% dplyr::select(-y)
trainy <- train %>% pull(y)
testx <- test %>% dplyr::select(-y)
testy <- test %>% pull(y)

dim(train)
dim(test)


pcasplit <- initial_split(BankPCA, prop = 0.7)
pcatrain <- training(pcasplit)
pcatest <- testing(pcasplit)

pcatrainx <- pcatrain %>% dplyr::select(-y)
pcatrainy <- pcatrain %>% pull(y)
pcatestx <- pcatest %>% dplyr::select(-y)
pcatesty <- pcatest %>% pull(y)

dim(pcatrain)
dim(pcatest)

pcatrainx <- pcatrain %>% dplyr::select(-y)
pcatrainy <- pcatrain %>% pull(y)
pcatestx <- pcatest %>% dplyr::select(-y)
pcatesty <- pcatest %>% pull(y)
```


```{r}
trainx <- train[, -which(names(train) == "y")]
trainx <- dummy_cols(trainx, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
trainy <- train$y
testx <- dummy_cols(testx, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
testy <- test$y


pcatrainx <- pcatrain[, -which(names(pcatrain) == "y")]
pcatrainx <- dummy_cols(pcatrainx, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
pcatrainy <- pcatrain$y
pcatestx <- dummy_cols(pcatestx, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
pcatesty <- pcatest$y
```


```{r}
model1 = qda(trainx, trainy)
yhat <- predict(model1, newdata=testx)$class
hm <- as.data.frame(table(yhat, testy))

ggplot(hm, aes(x = yhat, y = testy, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(yhat == testy) #84.36 accuracy
```


```{r}
model2 = lda(trainx, trainy)
yhat <- predict(model2, newdata=testx)$class
hm <- as.data.frame(table(yhat, testy))

ggplot(hm, aes(x = yhat, y = testy, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(yhat == testy) #90.88 accuracy
```


```{r}
pcamodel1 = qda(pcatrainx, pcatrainy)
pcayhat <- predict(pcamodel1, newdata=pcatestx)$class
hm <- as.data.frame(table(pcayhat, pcatesty))

ggplot(hm, aes(x = pcayhat, y = pcatesty, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(pcayhat == pcatesty) #85.027 accuracy
```


```{r}
pcamodel2 = lda(pcatrainx, pcatrainy)
pcayhat <- predict(pcamodel2, newdata=pcatestx)$class
hm <- as.data.frame(table(pcayhat, pcatesty))

ggplot(hm, aes(x = pcayhat, y = pcatesty, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(pcayhat == pcatesty) #91.62 accuracy
```


#Next is kNN

```{r, cache = TRUE}
m = 10; error = rep(0,m)
for (i in 1:m) {
  error[i] = sum(trainy != knn.cv(trainx, trainy, i))/length(trainy)
}

index = which(error == min(error)); index # Note, you might get different number due to random samples.

yhat = knn(train=trainx, cl=trainy, test=testx, k = index[1])
table(yhat, testy)

hm <- as.data.frame(table(yhat, testy))

ggplot(hm, aes(x = yhat, y = testy, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(yhat == testy) #86.95 accuracy
```

#KNN with PCA

```{r, cache= TRUE}
m = 10; error = rep(0,m)
for (i in 1:m) {
  error[i] = sum(pcatrainy != knn.cv(pcatrainx, pcatrainy, i))/length(pcatrainy)
}
```

```{r}
plot(1:m,error,type="l",lwd=3, xlab="k",ylab="error")

index = which(error == min(error)); index

pcayhat = knn(train=pcatrainx, cl=pcatrainy, test=pcatestx, k = index[1])
table(pcayhat, pcatesty)

hm <- as.data.frame(table(pcayhat, pcatesty))

ggplot(hm, aes(x = pcayhat, y = pcatesty, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10) +
  # following lines only increase text size (optional)
  theme(axis.text.x = element_text(size = 20),
      axis.text.y = element_text(size = 20),
      axis.title.x = element_text(size = 30),
      axis.title.y = element_text(size = 30))

mean(pcayhat == pcatesty) #91.58 accuracy
```